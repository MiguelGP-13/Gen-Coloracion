\documentclass[12pt]{article}
\setlength{\parindent}{0pt}
\usepackage{float}
\usepackage{graphicx}
\usepackage{openwork}

\title{Coloración de imágenes}
\author[1]{Álvaro Felipe Pérez}
\author[1]{Miguel Gómez Prieto}
\author[1]{Hugo Gómez-Caraballo López-Romero}
\author[1]{Carlos Serrano Pinós}
\affil[1]{Estudiante CDIA, Universidad Politécnica de Madrid, Madrid}
\date{}

\begin{document}

\maketitle

\begin{abstract}
La coloración automática de imágenes en escala de grises constituye un 
desafío relevante en visión por computador, al requerir la generación de 
información cromática plausible a partir de datos incompletos. En este trabajo 
se presenta un análisis comparativo de diferentes arquitecturas de aprendizaje 
profundo aplicadas a la coloración de imágenes, incluyendo Autoencoders (AE), 
Variational Autoencoders (VAE), redes UNet, Generative Adversarial Networks (GAN), 
modelos de difusión y enfoques guiados por texto. Los experimentos se realizaron 
sobre el conjunto de datos STL‑10 y un dataset complementario de flores, con el 
objetivo de evaluar la capacidad de cada modelo para reconstruir color de 
manera realista y coherente con el contenido semántico. Se discuten las ventajas 
y limitaciones de cada aproximación, así como la influencia de la resolución 
y el tipo de condicionamiento en la calidad perceptual de los resultados. Los hallazgos contribuyen a comprender el potencial y las fronteras actuales de las técnicas de coloración basadas en deep learning. \\
\textbf{Keywords:} Image colorization, Autoencoder, UNet, Generative Adversarial Network, 
Diffusion models, Text‑guided coloration, Computer vision
\end{abstract}

\clearpage
\tableofcontents
\clearpage

\input{Capítulos/1-introduccion}
\input{Capítulos/2-estado-cuestion}
\input{Capítulos/basics}
\input{Capítulos/gan}
\input{Capítulos/difussion}
\input{Capítulos/text-guided}
\input{Capítulos/7-conclusion}

\section*{Agradecimientos}
...

\printbibliography

\end{document}